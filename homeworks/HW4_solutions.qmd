---
title: "SCI 2025: Homework 4"
format: 
  pdf:
    geometry: margin=1in
    fontsize: 12pt
    linestretch: 1.5
    include-in-header:
      text: |
        \usepackage{amsmath}
        \usepackage{amsfonts}
execute:
  echo: true
  warning: false
  message: false
---

## Setup

The three homework problems this week are from Chapter 6 of the textbook.

## Question 1: 6M1

Modify the DAG on page 186 to include the variable $V$, an unobserved cause of $C$ and $Y$: $C \leftarrow V \rightarrow Y$. Reanalyze the DAG. How many paths connect $X$ to $Y$? Which must be closed? Which variables should you condition on now?

```{r}
library(dagitty)
dag <- dagitty("dag {
  A -> U
  A -> C
  U -> X
  U -> B
  C -> B
  C -> Y
  V -> C
  V -> Y
  X -> Y
}")

# Set coordinates to better match the layout in the image
coordinates(dag) <- list(
  x = c(A = 0, U = -2, C = 2, B = 0, V = 4, X = -4, Y = 4),
  y = c(A = -4, U = -2, C = 0, B = 2, V = 2, X = 4, Y = 4)
)


plot(dag)
```

There are now 5 (instead of just 3) paths connecting $X$ to $Y$:

1. $X \rightarrow Y$

2. $X \leftarrow U \rightarrow B \leftarrow C \rightarrow Y$

3. $X \leftarrow U \rightarrow B \leftarrow C \leftarrow V \rightarrow Y$

4. $X \leftarrow U \leftarrow A \rightarrow C \rightarrow Y$

5. $X \leftarrow U \leftarrow A \rightarrow C \leftarrow V \rightarrow Y$

2 and 3 are closed already (colliders); 4 and 5 need to be closed. The only valid adjustment set is A alone.

```{r}
adjustmentSets(dag, exposure = "X", outcome = "Y") # note that A is the only valid adjustment set 
# because it doesn't include unobserved variables
```
## Question 2: 6M2

Sometimes, in order to avoid multicollinearity, people inspect pairwise correlations among predictors before including them in a model. This is a bad procedure, because what matters is the conditional association, not the association before the variables are included in the model. To highlight this, consider the DAG $X \rightarrow Z \rightarrow Y$. Simulate data from this DAG so that the correlation between $X$ and $Z$ is very large. Then include both in a model prediction $Y$. Do you observe any multicollinearity? Why or why not? What is different from the legs example in the chapter?

```{r}
N <- 500
X <- rnorm(N, 0, 1) # going to the gym
Z <- rnorm(N, X*2.5, 1) # exercising
Y <- rnorm(N, Z, 1) # calories burned

cor(X, Z)

d <- data.frame(X, Z, Y)

library(rethinking)

model <- quap(
  alist(
    Y ~ dnorm(mu, sigma),
    mu <- a + bX*X + bZ*Z,
    a ~ dnorm(0, 1),
    bX ~ dnorm(0, 1),
    bZ ~ dnorm(0, 1),
    sigma ~ dexp(1)
  ),
  data = d
)

precis(model)
```

The parameter estimates look fine (lack of multicollinearity), despite high correlation between $X$ and $Z$. The difference here is: (1) mediation rather than common causes of $Y$ and (2) there is not a perfect correlation between $X$ and $Z$.

## Question 3: 6M3

Learning to analyze DAGs requires practice. For each of the four DAGs below, state which variables, if any, you must adjust for (condition on) to estimate the total causal influence of $X$ on $Y$.

![](img/6M3_DAGS.png)

1. Adjust for $Z$ ($Z$ is a confounder)
2. No adjustment ($Z$ is a mediator/collider)
3. No adjustment ($Z$ is a collider)
4. Adjust for $A$ ($Z$ is a mediator, $A$ creater a backdoor path between $X$ and $Y$)

Key to this question: the direction of the arrow matters a lot!

## Question 4

Can you think of potential examples of collider bias from your own field or a related literature? Do you think the bias is likely to be positive or negative (with respect to the causal effect of interest)? Positive bias would mean that the estimated relationship between the focal variable and the outcome is too strong, while negative bias would mean that the estimated relationship is too weak.

Example from evolutionary biology: survival bias in comparative studies. If two traits both reduce the likelihood that a species will go extinct, this can induce a spurious positive association between the traits if we only look at extant species.
